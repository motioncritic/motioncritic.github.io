<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <!-- <title>Academic Project Page</title> -->
  <title>Aligning Human Motion Generation with Human Perceptions</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
	    tex2jax: {
	        inlineMath: [['$','$'], ['\\(','\\)']],
	        processEscapes: true
	    }
	});
    </script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="xtitle is-1 publication-title">Aligning Human Motion Generation with Human Perceptions</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://ou524u.github.io/" target="_blank">Haoru Wang<sup>1,†</sup></a>
              </span>
              <span class="author-block">
                <a href="https://walter0807.github.io/" target="_blank">Wentao Zhu<sup>1,†</sup></a>
              </span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Luyi Miao<sup>1</sup></a>
              </span>
              <span class="author-block">
                <a href="FORTH AUTHOR PERSONAL LINK" target="_blank">Yishu Xu<sup>1</sup></a>
              </span>
              <span class="author-block">
                <a href="THIRD LAST AUTHOR PERSONAL LINK" target="_blank">Feng Gao<sup>1</sup></a>
              </span>
              <span class="author-block">
                <a href="https://www.qitian1987.com/index.html" target="_blank">Qi Tian<sup>2</sup></a>
              </span>
              <span class="author-block">
                <a href="https://cfcs.pku.edu.cn/wangyizhou/" target="_blank">Yizhou Wang<sup>1</sup></a>
              </span>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <sup>1</sup> Peking University<br>
                  <sup>2</sup> Huawei Cloud<br>
                  <!-- Submitted to NeurIPS2024 Dataset & Benchmark Track -->
                </span>
              </div>
              <div class="is-size-6">
                <p><sup>†</sup> Lead author</p>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2404.09445v1" target="_blank" class="external-link ">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Supplementary PDF link -->
                  <!-- <span class="link-block">
                    <a href="static/pdfs/supplementary_material.pdf" target="_blank" class="external-link ">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ou524u/AlignHP" target="_blank" class="external-link ">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank" class="external-link ">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
  </section>

  <!-- 
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="marquee-wrapper">
        <div class="container">
          <div class="marquee-block">
            <div class="marquee-inner to-left">
              <span>
                <div class="marquee-item">
                  <img src="static/images/carousel1.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">1</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel2.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">2</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel3.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">3</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">4</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel5.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">5</p>
                </div>
              </span>
              <span>
                <div class="marquee-item">
                  <img src="static/images/carousel1.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">1</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel2.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">2</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel3.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">3</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">4</p>
                </div>
                <div class="marquee-item">
                  <img src="static/images/carousel5.jpg" alt="MY ALT TEXT" />
                  <p class="text-white">5</p>
                </div>
              </span>
            </div>
          </div>
        </div>
  </section> 
  -->

  <!-- New section for images -->
  <div class="image-wrapper section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">Overview</h2>
          <div class="image-item">
            <img src="static/images/framework.png" alt="Framework" class="responsive-image">
            <p class="image-caption">Framework Overview. We collect MotionPercept, a large-scale, human-annotated
              dataset for
              motion perceptual evaluation, where human subjects select the best quality motion in multiple-choice
              questions.
              Using this dataset, we train MotionCritic to automatically judge motion quality in alignment with human
              perceptions,
              offering better quality metrics. Additionally, we show that MotionCritic can enhance existing motion
              generators
              with
              minimal fine-tuning.</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Paper abstract -->
  <!-- <section class="section hero is-light"> -->
  <section class="section hero is-white">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">Abstract</h2>
          <div class="content has-text-justified">
            <p>Human motion generation is a critical task with a wide spectrum of applications. Achieving high realism
              in
              generated motions requires naturalness, smoothness, and plausibility. However, current evaluation metrics
              often rely on error with ground-truth, simple heuristics, or distribution distances and do not align well
              with human perceptions. In this work, we propose a data-driven approach to bridge this gap by introducing
              a large-scale human perceptual evaluation dataset, MotionPercept, and a human motion critic model,
              MotionCritic, that
              capture human perceptual preferences. Our critic model offers a more accurate metric for assessing motion
              quality and could be readily integrated into the motion generation pipeline to enhance generation quality.
              Extensive experiments demonstrate the effectiveness of our approach in both evaluating and improving the
              quality of generated human motions by aligning with human perceptions.</p>
          </div>
        </div>
      </div>
    </div>
  </section>



  <!-- MotionPercept section -->
  <div class="image-wrapper section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">MotionPercept</h2>
          <div class="image-item">
            <p class="image-caption">We first introduce a large-scale human perceptual evaluation dataset,
              MotionPercept.</p>
          </div>
          <div class="image-item">
            <video src="static/videos/00-1.mp4" controls loop class="responsive-image"></video>
            <p class="image-caption">
              We implement a pipeline for data collection and annotation. First, we collect
              generated human motion sequence pairs, and then instruct the annotators to select the best candidate. The
              best option should be the most natural, visually pleasing, and free of artifacts.</p>
          </div>
        </div>
      </div>
    </div>
  </div>


  <!-- MotionCritic Section -->
  <div class="image-wrapper section hero is-white">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">MotionCritic</h2>
          <div class="image-item">
            <img src="static/images/pipeline.png" alt="Pipeline" class="responsive-image">
            <p class="image-caption">(I) Critic model training process. We sample human motion pairs $\mathbf{x}^{(h)},
              \mathbf{x}^{(l)}$ annotated with human preferences, upon which the critic model produces score pairs. We
              use perceptual alignment loss $L_\text{Percept}$ to learn from the human perceptions.
              % <br>
              (II) Motion generation with critic model supervision. We intercept MDM sampling process at random timestep
              $t$ and perform single-step prediction. Critic model computes the score $s$ based on the generated motion
              $\mathbf{x}_0'$, which is further used to calculate motion critic loss $L_\text{Critic}$.
              %
              KL loss $L_\text{KL}$ is introduced between $\mathbf{x}_0'$ and last-time generation result
              $\widetilde{\mathbf{x}_0}'$.</p>
          </div>
        </div>
      </div>
    </div>
  </div>



  <div class="image-wrapper section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">MotionCritic as Motion Quality Metric</h2>
          <div class="columns is-multiline">
            <!-- First video and caption -->
            <div class="column is-half">
              <div class="video-item">
                <video src="static/videos/04-1.mp4" controls autoplay class="responsive-video"></video>
              </div>
            </div>
            <!-- Second video and caption -->
            <div class="column is-half">
              <div class="video-item">
                <video src="static/videos/05-1.mp4" controls autoplay class="responsive-video"></video>
              </div>
            </div>
            <p class="image-caption">The MotionCritic model scores motion based on human preference alignment and can
              serve as a motion quality metric. Here, we present the results on the test set, demonstrating that the
              critic score effectively reflects motion quality.</p>
          </div>
        </div>
      </div>
    </div>
  </div>



  <div class="image-wrapper section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">MotionCritic as Training Supervision</h2>
          <div class="image-item">
            <p class="image-caption">We show that fine-tuning with our critic model significantly improves motion
              quality with higher critic scores. Notably, this requires only a few hundred iterations, demonstrating the
              effectiveness and efficiency of our method.</p>
          </div>
          <div class="image-item">
            <video src="static/videos/01-1.mp4" controls loop class="responsive-image"></video>
            <video src="static/videos/02-1.mp4" controls loop class="responsive-image"></video>
            <video src="static/videos/03-1.mp4" controls loop class="responsive-image"></video>
          </div>
        </div>
      </div>
    </div>
  </div>



  <style>
    .image-wrapper,
    .section.hero.is-light {
      padding: 3rem 1.5rem;
      background-color: #f5f5f5;
    }

    .section.hero.is-white {
      padding: 3rem 1.5rem;
      background-color: #ffffff;
    }

    .container.is-max-desktop {
      max-width: 960px;
      margin: auto;
    }

    .columns.is-centered {
      display: flex;
      justify-content: center;
    }

    .column.is-four-fifths {
      width: 90%;
    }

    .image-item {
      text-align: left;
    }

    .responsive-image {
      max-width: 100%;
      height: auto;
    }

    .image-caption {
      margin-top: 10px;
      font-size: 1.2em;
      color: #000000;
      padding: 10px;
      background-color: rgba(1, 1, 1, 0);
      text-align: left;
    }

    .content {
      font-size: 1.2em;
    }

    .title.is-3 {
      font-size: 2em;
      text-align: center;
    }

    .has-text-justified {
      text-align: justify;
    }

    .has-text-centered {
      text-align: center;
    }
  </style>



  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{motionpercept2024,
        title={Aligning Motion Generation with Human Perceptions},
        author={Wang, Haoru and Zhu, Wentao and Miao, Luyi and Xu, Yishu and Gao, Feng and Tian, Qi and Wang, Yizhou},
        year={2024}
    }</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/vinthony/project-page-template">modification
                version</a> of <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Aligning Human Motion Generation with Human Perceptions</a> from <a
                href="https://github.com/vinthony">vinthony</a>.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>